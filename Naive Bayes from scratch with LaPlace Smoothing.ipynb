{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('SMSSpamCollection',sep='\\t',header=None,names = ['Label','SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train,df_test = train_test_split(df,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\os_sonnh1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df_train.SMS = df_train.SMS.str.replace(pat='\\W',repl=' ').str.lower()\n",
    "df_train.SMS = df_train.SMS.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for i in df_train.SMS:\n",
    "    for v in i:\n",
    "        vocab.append(v)\n",
    "vocab = set(vocab)\n",
    "vocab = list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7764"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {}\n",
    "for w in vocab:\n",
    "    word_counts_per_sms[w] = [0] * len(df_train.SMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,sms in enumerate(df_train.SMS):\n",
    "    for w in sms:\n",
    "        word_counts_per_sms[w][idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = pd.concat([df_train,df_word],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = fin_df.drop(fin_df[fin_df.Label.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4457"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df = fin_df.fillna(0)\n",
    "len(fin_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_ham = list(fin_df.Label.value_counts()/len(fin_df))[0]\n",
    "P_spam = list(fin_df.Label.value_counts()/len(fin_df))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham_tr = df_train[df_train.Label == 'ham']\n",
    "df_spam_tr = df_train[df_train.Label == 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_vocab_list = []\n",
    "for i in df_ham_tr.SMS:\n",
    "    for w in i:\n",
    "        ham_vocab_list.append(w)\n",
    "ham_vocab_set = set(ham_vocab_list)\n",
    "N_ham = len(ham_vocab_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_vocab_list = []\n",
    "for i in df_spam_tr.SMS:\n",
    "    for w in i:\n",
    "        spam_vocab_list.append(w)\n",
    "spam_vocab_set = set(spam_vocab_list)\n",
    "N_spam = len(spam_vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "N_vocab = N_ham + N_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_ham_dict = {}\n",
    "P_spam_dict = {}\n",
    "#LaPlace smoothing\n",
    "for i in vocab:\n",
    "    P_ham_dict[i] = (ham_vocab_list.count(i) + alpha)/(N_ham + alpha * N_vocab) \n",
    "    P_spam_dict[i] = (spam_vocab_list.count(i) + alpha)/(N_spam + alpha * N_vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = P_spam\n",
    "    p_ham_given_message = P_ham\n",
    "    \n",
    "    for i in message:\n",
    "        if i in P_spam_dict:\n",
    "            p_spam_given_message *= P_spam_dict[i]\n",
    "        if i in P_ham_dict:\n",
    "            p_ham_given_message *= P_ham_dict[i]\n",
    "    \n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return'Equal proabilities, have a human classify this!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\os_sonnh1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well thats nice. Too bad i cant eat it</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>spam</td>\n",
       "      <td>Promotion Number: 8714714 - UR awarded a City ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4217</th>\n",
       "      <td>ham</td>\n",
       "      <td>Er mw im filled tuth is aight</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>ham</td>\n",
       "      <td>i dnt wnt to tlk wid u</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok I'm gonna head up to usf in like fifteen mi...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS predicted\n",
       "5217   ham             Well thats nice. Too bad i cant eat it       ham\n",
       "3679  spam  Promotion Number: 8714714 - UR awarded a City ...      spam\n",
       "4217   ham                      Er mw im filled tuth is aight       ham\n",
       "1381   ham                             i dnt wnt to tlk wid u       ham\n",
       "476    ham  Ok I'm gonna head up to usf in like fifteen mi...       ham"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predicted'] = df_test['SMS'].apply(classify)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1063\n",
      "Incorrect: 52\n",
      "Accuracy: 0.9533632286995516\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = df_test.shape[0]\n",
    "    \n",
    "for row in df_test.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
